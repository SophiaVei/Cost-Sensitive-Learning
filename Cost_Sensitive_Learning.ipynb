{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ">[Rebalancing](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=gORaPtwjq5d6)\n",
        "\n",
        ">>[Random Forest](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=NRRtCIPUzHwb)\n",
        "\n",
        ">>[SVM](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=MekvhT9uzPDD)\n",
        "\n",
        ">>[Naive Bayes](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=8IGWMNN602Qz)\n",
        "\n",
        ">[Sample Weights](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=hzNRVDfu1exm)\n",
        "\n",
        ">>[Random Forest](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=6296FJdf2szo)\n",
        "\n",
        ">>[SVM](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=slNmL1gn213a)\n",
        "\n",
        ">>[Naive Bayes](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=Bztd07ER3BjK)\n",
        "\n",
        ">[Minimizing Expected Cost](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=23amfjZBeSSW)\n",
        "\n",
        ">>[Random Forest](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=o_GcmjqHeVNF)\n",
        "\n",
        ">>[SVM](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=_g0cVh7meYC2)\n",
        "\n",
        ">>[Naive Bayes](#updateTitle=true&folderId=1Vf62KS3fdi5XEz3Eibgj40ZsrrKTVRfI&scrollTo=Xc30xyX_eaRj)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "wHAGXjlu1YKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project is divided by methods (sampling, weighing and minimizing expected cost) and within each method we use three classifiers (Random Forest, SVM and Naive Bayes). At the end of each method, we are giving some conclusions about all three classifiers that were tested with this technique."
      ],
      "metadata": {
        "id": "2X2OL33t0Mlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note on how the cost matrix is defined in our code:\n",
        "\n",
        "In the Statlog (German Credit Data) Data Set the labels are defined as:\n",
        "*(1 = Good, 2 = Bad)*.\n",
        "\n",
        "*The rows represent the actual classification and the columns the predicted classification*, while in general we use the transposed version.\n",
        "**It is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).**\n",
        "\n",
        "This means that the cost matrix here is defined as: cost_m = [[0,1],[5,0]] but if we transpose it we get: cost_m = [[0,5],[1,0]], indicating again that the costs of a false positive (incorrectly saying an applicant is a good credit risk) is higher than the cost of a false negative (incorrectly saying an applicant is a bad credit risk)."
      ],
      "metadata": {
        "id": "8-DhWB5mjKOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import compute_sample_weight\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from joblib import dump, load\n",
        "from collections import Counter\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "2e1Dqv0TEwij"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric\"\n",
        "data = pd.read_csv(url, header=None, sep='\\s+')\n",
        "\n",
        "# define target column and create a DataFrame\n",
        "target_col = 24\n",
        "target_names = ['good', 'bad']\n",
        "frame = pd.DataFrame(data[target_col], columns=['target'])\n",
        "frame['target'].value_counts(sort=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARFamRb8falh",
        "outputId": "153014f3-5f8c-474d-ce73-9bf3eabde4b9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: target, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into features and labels\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "print(Counter(y_train))\n",
        "# define the cost matrix\n",
        "cost_m = np.array([[0, 1], [5, 0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbmqhScPQPht",
        "outputId": "cf6aad99-62a8-41b1-e810-058f90de1bfa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 486, 2: 214})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rebalancing"
      ],
      "metadata": {
        "id": "gORaPtwjq5d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "NRRtCIPUzHwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "print(\"without sampling\")\n",
        "print(Counter(y_train))\n",
        "#1: 486, 2: 214\n",
        "\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with undersampling\")\n",
        "sampler = RandomUnderSampler(sampling_strategy={1: 486, 2: 114}, random_state=1) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with oversampling\")\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 586, 2: 214}, random_state=1) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with combination\")\n",
        "sampler = RandomUnderSampler(sampling_strategy={1: 486, 2: 114}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 586, 2: 114}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_rs, y_rs)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PC7W1yeq5By",
        "outputId": "5707c74c-f9c7-46d0-d1bf-3ba53c629047"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without sampling\n",
            "Counter({1: 486, 2: 214})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.79      0.89      0.84       214\n",
            "         bad       0.61      0.43      0.50        86\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.70      0.66      0.67       300\n",
            "weighted avg       0.74      0.76      0.74       300\n",
            "\n",
            "[[190  49]\n",
            " [ 24  37]]\n",
            "169\n",
            "\n",
            "with undersampling\n",
            "Counter({1: 486, 2: 114})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.75      0.96      0.85       214\n",
            "         bad       0.70      0.22      0.34        86\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.73      0.59      0.59       300\n",
            "weighted avg       0.74      0.75      0.70       300\n",
            "\n",
            "[[206  67]\n",
            " [  8  19]]\n",
            "107\n",
            "\n",
            "with oversampling\n",
            "Counter({1: 586, 2: 214})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.78      0.90      0.83       214\n",
            "         bad       0.58      0.36      0.45        86\n",
            "\n",
            "    accuracy                           0.74       300\n",
            "   macro avg       0.68      0.63      0.64       300\n",
            "weighted avg       0.72      0.74      0.72       300\n",
            "\n",
            "[[192  55]\n",
            " [ 22  31]]\n",
            "165\n",
            "\n",
            "with combination\n",
            "Counter({1: 586, 2: 114})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.76      0.96      0.85       214\n",
            "         bad       0.72      0.27      0.39        86\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.74      0.61      0.62       300\n",
            "weighted avg       0.75      0.76      0.72       300\n",
            "\n",
            "[[205  63]\n",
            " [  9  23]]\n",
            "108\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "MekvhT9uzPDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "print(\"without sampling\")\n",
        "print(Counter(y_train))\n",
        "#1: 486, 2: 214\n",
        "\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with undersampling\")\n",
        "sampler = RandomUnderSampler(sampling_strategy={1: 486, 2: 114}, random_state=1) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with oversampling\")\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 586, 2: 214}, random_state=1) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with combination\")\n",
        "sampler = RandomUnderSampler(sampling_strategy={1: 486, 2: 114}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 586, 2: 114}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_rs, y_rs)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-VKxi-yzRGx",
        "outputId": "2c876cb0-07f7-4306-f138-0107ccfaef42"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without sampling\n",
            "Counter({1: 486, 2: 214})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.82      0.87      0.85       214\n",
            "         bad       0.62      0.53      0.57        86\n",
            "\n",
            "    accuracy                           0.77       300\n",
            "   macro avg       0.72      0.70      0.71       300\n",
            "weighted avg       0.77      0.77      0.77       300\n",
            "\n",
            "[[186  40]\n",
            " [ 28  46]]\n",
            "180\n",
            "\n",
            "with undersampling\n",
            "Counter({1: 486, 2: 114})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.76      0.94      0.84       214\n",
            "         bad       0.66      0.27      0.38        86\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.71      0.61      0.61       300\n",
            "weighted avg       0.73      0.75      0.71       300\n",
            "\n",
            "[[202  63]\n",
            " [ 12  23]]\n",
            "123\n",
            "\n",
            "with oversampling\n",
            "Counter({1: 586, 2: 214})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.78      0.89      0.83       214\n",
            "         bad       0.57      0.37      0.45        86\n",
            "\n",
            "    accuracy                           0.74       300\n",
            "   macro avg       0.68      0.63      0.64       300\n",
            "weighted avg       0.72      0.74      0.72       300\n",
            "\n",
            "[[190  54]\n",
            " [ 24  32]]\n",
            "174\n",
            "\n",
            "with combination\n",
            "Counter({1: 586, 2: 114})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.73      0.97      0.83       214\n",
            "         bad       0.59      0.12      0.19        86\n",
            "\n",
            "    accuracy                           0.72       300\n",
            "   macro avg       0.66      0.54      0.51       300\n",
            "weighted avg       0.69      0.72      0.65       300\n",
            "\n",
            "[[207  76]\n",
            " [  7  10]]\n",
            "111\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes"
      ],
      "metadata": {
        "id": "8IGWMNN602Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "clf = GaussianNB()\n",
        "print(\"without sampling\")\n",
        "print(Counter(y_train))\n",
        "#1: 486, 2: 214\n",
        "\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with undersampling\")\n",
        "sampler = RandomUnderSampler(sampling_strategy={1: 486, 2: 114}, random_state=1) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with oversampling\")\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 586, 2: 214}, random_state=1) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"with combination\")\n",
        "sampler = RandomUnderSampler(sampling_strategy={1: 486, 2: 114}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "sampler = RandomOverSampler(sampling_strategy={1: 586, 2: 114}, random_state=1)\n",
        "X_rs, y_rs = sampler.fit_resample(X_rs, y_rs)\n",
        "print(Counter(y_rs))\n",
        "\n",
        "\n",
        "model = clf.fit(X_rs, y_rs)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHtt-VJs06ZO",
        "outputId": "e33b6982-71e6-49fb-fd27-972a9cfd95eb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without sampling\n",
            "Counter({1: 486, 2: 214})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.84      0.73      0.78       214\n",
            "         bad       0.50      0.65      0.56        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.67      0.69      0.67       300\n",
            "weighted avg       0.74      0.71      0.72       300\n",
            "\n",
            "[[157  30]\n",
            " [ 57  56]]\n",
            "315\n",
            "\n",
            "with undersampling\n",
            "Counter({1: 486, 2: 114})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.85      0.81      0.83       214\n",
            "         bad       0.57      0.64      0.60        86\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.71      0.72      0.72       300\n",
            "weighted avg       0.77      0.76      0.76       300\n",
            "\n",
            "[[173  31]\n",
            " [ 41  55]]\n",
            "236\n",
            "\n",
            "with oversampling\n",
            "Counter({1: 586, 2: 214})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.83      0.77      0.80       214\n",
            "         bad       0.51      0.62      0.56        86\n",
            "\n",
            "    accuracy                           0.72       300\n",
            "   macro avg       0.67      0.69      0.68       300\n",
            "weighted avg       0.74      0.72      0.73       300\n",
            "\n",
            "[[164  33]\n",
            " [ 50  53]]\n",
            "283\n",
            "\n",
            "with combination\n",
            "Counter({1: 586, 2: 114})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.85      0.82      0.83       214\n",
            "         bad       0.58      0.63      0.60        86\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.71      0.72      0.72       300\n",
            "weighted avg       0.77      0.76      0.77       300\n",
            "\n",
            "[[175  32]\n",
            " [ 39  54]]\n",
            "227\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In all three classifiers we notice a decrease in the cost, compared to not sampling. Specifically, in Random Forest we achieve the smallest cost with Undersampling (107 compared to the initial which is 169) but also with combination. In SVM the smallest cost is achieved with combination (111 compared to the initial which is 180). Last but not least, for the Naive Bayes classifier the best cost is achieved, once again, by combination (227 compared to the initial which is 315). Overall, it is obvious that the costs of a false positive - incorrectly saying an applicant is a good credit risk, is higher than the cost of a false negative - incorrectly saying an applicant is a bad credit risk. Our best strategy, in general for all classifiers here is to use combination.\n",
        "\n",
        "(we note that besides the decrease in cost, judging from f1 score, the Random Forest and Naive Bayes classifier get the best results in f1 scores, especially Naive Bayes, once again, using combination of oversampling and undersampling, which suits well the the additional reduction of the cost.)"
      ],
      "metadata": {
        "id": "8fN6Nj9lm5s7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Weights"
      ],
      "metadata": {
        "id": "hzNRVDfu1exm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "6296FJdf2szo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
        "\n",
        "print(\"without weights\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "pred_test = model.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"\\nwith weights\")\n",
        "weights = np.zeros(y_train.shape[0])\n",
        "weights[np.where(y_train == 1)] = 5;\n",
        "weights[np.where(y_train == 2)] = 1;\n",
        "model = clf.fit(X_train, y_train, weights)\n",
        "pred_test = clf.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T \n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"\\nwith weights (alternative)\")\n",
        "clf.class_weight = {1: 5, 2: 1}\n",
        "model = clf.fit(X_train, y_train)\n",
        "pred_test = model.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T\n",
        "print(conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1jIVzCL1mGK",
        "outputId": "bff2d997-2140-4f1f-fa74-31a2ccbb04dd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without weights\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.80      0.88      0.84       214\n",
            "         bad       0.61      0.45      0.52        86\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.71      0.67      0.68       300\n",
            "weighted avg       0.75      0.76      0.75       300\n",
            "\n",
            "[[189  47]\n",
            " [ 25  39]]\n",
            "172\n",
            "\n",
            "\n",
            "with weights\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.78      0.86      0.82       214\n",
            "         bad       0.54      0.41      0.46        86\n",
            "\n",
            "    accuracy                           0.73       300\n",
            "   macro avg       0.66      0.63      0.64       300\n",
            "weighted avg       0.71      0.73      0.72       300\n",
            "\n",
            "[[184  51]\n",
            " [ 30  35]]\n",
            "201\n",
            "\n",
            "\n",
            "with weights (alternative)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.78      0.86      0.82       214\n",
            "         bad       0.54      0.41      0.46        86\n",
            "\n",
            "    accuracy                           0.73       300\n",
            "   macro avg       0.66      0.63      0.64       300\n",
            "weighted avg       0.71      0.73      0.72       300\n",
            "\n",
            "[[184  51]\n",
            " [ 30  35]]\n",
            "201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "slNmL1gn213a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel='linear')\n",
        "\n",
        "print(\"without weights\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "pred_test = model.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T \n",
        "print('confusion matrix:',conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"\\nwith weights\")\n",
        "# Create the sample weights according to y\n",
        "weights = np.zeros(y_train.shape[0])\n",
        "weights[np.where(y_train == 1)] = 5;\n",
        "weights[np.where(y_train == 2)] = 1;\n",
        "model = clf.fit(X_train, y_train, weights)\n",
        "pred_test = clf.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T \n",
        "print('confusion matrix:',conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"\\nwith weights (alternative)\")\n",
        "clf.class_weight = {1: 5, 2: 1}\n",
        "model = clf.fit(X_train, y_train)\n",
        "pred_test = model.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T\n",
        "print('confusion matrix:',conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEv4N28k21IK",
        "outputId": "c6d3b484-959b-4511-8667-9f9c86b2d80c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without weights\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.82      0.87      0.85       214\n",
            "         bad       0.62      0.53      0.57        86\n",
            "\n",
            "    accuracy                           0.77       300\n",
            "   macro avg       0.72      0.70      0.71       300\n",
            "weighted avg       0.77      0.77      0.77       300\n",
            "\n",
            "confusion matrix: [[186  40]\n",
            " [ 28  46]]\n",
            "180\n",
            "\n",
            "\n",
            "with weights\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.71      1.00      0.83       214\n",
            "         bad       0.00      0.00      0.00        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.36      0.50      0.42       300\n",
            "weighted avg       0.51      0.71      0.59       300\n",
            "\n",
            "confusion matrix: [[214  86]\n",
            " [  0   0]]\n",
            "86\n",
            "\n",
            "\n",
            "with weights (alternative)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.71      1.00      0.83       214\n",
            "         bad       0.00      0.00      0.00        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.36      0.50      0.42       300\n",
            "weighted avg       0.51      0.71      0.59       300\n",
            "\n",
            "confusion matrix: [[214  86]\n",
            " [  0   0]]\n",
            "86\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes"
      ],
      "metadata": {
        "id": "Bztd07ER3BjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GaussianNB()\n",
        "\n",
        "print(\"without weights\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "pred_test = model.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T\n",
        "print('confusion matrix:',conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"\\nwith weights\")\n",
        "# now create the sample weights according to y\n",
        "weights = np.zeros(y_train.shape[0])\n",
        "weights[np.where(y_train == 1)] = 5;\n",
        "weights[np.where(y_train == 2)] = 1;\n",
        "model = clf.fit(X_train, y_train, weights)\n",
        "pred_test = clf.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T \n",
        "print('confusion matrix:',conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n",
        "\n",
        "print(\"\\nwith weights (alternative)\")\n",
        "clf.class_weight = {1: 5, 2: 1}\n",
        "model = clf.fit(X_train, y_train)\n",
        "pred_test = model.predict(X_test)\n",
        "print(classification_report(y_test, pred_test, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, pred_test).T\n",
        "print('confusion matrix:',conf_m)\n",
        "loss = np.sum(conf_m * cost_m)\n",
        "print(\"%d\\n\" %loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQ823DA3DYE",
        "outputId": "4036e2a7-2a1b-4d27-cf8d-bafba6524636"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without weights\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.84      0.73      0.78       214\n",
            "         bad       0.50      0.65      0.56        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.67      0.69      0.67       300\n",
            "weighted avg       0.74      0.71      0.72       300\n",
            "\n",
            "confusion matrix: [[157  30]\n",
            " [ 57  56]]\n",
            "315\n",
            "\n",
            "\n",
            "with weights\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.79      0.89      0.84       214\n",
            "         bad       0.60      0.41      0.49        86\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.70      0.65      0.66       300\n",
            "weighted avg       0.74      0.75      0.74       300\n",
            "\n",
            "confusion matrix: [[191  51]\n",
            " [ 23  35]]\n",
            "166\n",
            "\n",
            "\n",
            "with weights (alternative)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.84      0.73      0.78       214\n",
            "         bad       0.50      0.65      0.56        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.67      0.69      0.67       300\n",
            "weighted avg       0.74      0.71      0.72       300\n",
            "\n",
            "confusion matrix: [[157  30]\n",
            " [ 57  56]]\n",
            "315\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying weights, in general, we also get decreases in cost. In SVM we droped from 180 to 86 and with Naive Bayes, from 315 we droped to 166. Both of these cases worked well.\n",
        "However, in Random Forest, not only did we not have a decrease, but instead, we got an even higher cost!\n",
        "\n",
        "Judging from our classification reports, Naive Bayes, besides reducing the cost greatly, it has a very good performance on the metrics (eg. recall & f1)."
      ],
      "metadata": {
        "id": "I2eU_BmPqcEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Minimizing Expected Cost"
      ],
      "metadata": {
        "id": "23amfjZBeSSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "o_GcmjqHeVNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate a Random Forest classifier without cost minimization\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "print(\"No cost minimization\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "print(\"\\ncost minimization without probability calibration\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "# Train and evaluate a Random Forest classifier with cost minimization (sigmoid calibration)\n",
        "print(\"\\nCost minimization with sigmoid calibration\")\n",
        "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
        "model = cc.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "print(\"\\ncost minimization with isotonic calibration\")\n",
        "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
        "model = cc.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW74XzPFeXqk",
        "outputId": "0e4c2e7d-ec4f-4d35-a7c1-13622d4fdcf1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No cost minimization\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.79      0.89      0.84       214\n",
            "         bad       0.61      0.43      0.50        86\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.70      0.66      0.67       300\n",
            "weighted avg       0.74      0.76      0.74       300\n",
            "\n",
            "[[190  49]\n",
            " [ 24  37]]\n",
            "169\n",
            "\n",
            "cost minimization without probability calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.72      1.00      0.84       214\n",
            "         bad       0.75      0.03      0.07        86\n",
            "\n",
            "    accuracy                           0.72       300\n",
            "   macro avg       0.73      0.52      0.45       300\n",
            "weighted avg       0.73      0.72      0.61       300\n",
            "\n",
            "[[213  83]\n",
            " [  1   3]]\n",
            "88\n",
            "\n",
            "Cost minimization with sigmoid calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.73      0.99      0.84       214\n",
            "         bad       0.78      0.08      0.15        86\n",
            "\n",
            "    accuracy                           0.73       300\n",
            "   macro avg       0.75      0.54      0.49       300\n",
            "weighted avg       0.74      0.73      0.64       300\n",
            "\n",
            "[[212  79]\n",
            " [  2   7]]\n",
            "89\n",
            "\n",
            "cost minimization with isotonic calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.74      0.98      0.84       214\n",
            "         bad       0.73      0.13      0.22        86\n",
            "\n",
            "    accuracy                           0.74       300\n",
            "   macro avg       0.74      0.55      0.53       300\n",
            "weighted avg       0.74      0.74      0.66       300\n",
            "\n",
            "[[210  75]\n",
            " [  4  11]]\n",
            "95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "_g0cVh7meYC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate an SVM classifier without cost minimization\n",
        "clf = SVC(kernel='linear', probability=True)\n",
        "print(\"No cost minimization\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "print(\"\\ncost minimization without probability calibration\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "# Train and evaluate an SVM classifier with cost minimization (sigmoid calibration)\n",
        "print(\"\\nCost minimization with sigmoid calibration\")\n",
        "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
        "model = cc.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "print(\"\\ncost minimization with isotonic calibration\")\n",
        "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
        "model = cc.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q2rcc4veZu-",
        "outputId": "753cdf85-f07c-4b46-fa69-d944f5f43be3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No cost minimization\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.82      0.87      0.85       214\n",
            "         bad       0.62      0.53      0.57        86\n",
            "\n",
            "    accuracy                           0.77       300\n",
            "   macro avg       0.72      0.70      0.71       300\n",
            "weighted avg       0.77      0.77      0.77       300\n",
            "\n",
            "[[186  40]\n",
            " [ 28  46]]\n",
            "180\n",
            "\n",
            "cost minimization without probability calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.72      0.98      0.83       214\n",
            "         bad       0.50      0.05      0.09        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.61      0.51      0.46       300\n",
            "weighted avg       0.66      0.71      0.62       300\n",
            "\n",
            "[[210  82]\n",
            " [  4   4]]\n",
            "102\n",
            "\n",
            "Cost minimization with sigmoid calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.72      0.99      0.83       214\n",
            "         bad       0.50      0.03      0.07        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.61      0.51      0.45       300\n",
            "weighted avg       0.66      0.71      0.61       300\n",
            "\n",
            "[[211  83]\n",
            " [  3   3]]\n",
            "98\n",
            "\n",
            "cost minimization with isotonic calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.73      0.97      0.83       214\n",
            "         bad       0.56      0.10      0.18        86\n",
            "\n",
            "    accuracy                           0.72       300\n",
            "   macro avg       0.65      0.54      0.50       300\n",
            "weighted avg       0.68      0.72      0.64       300\n",
            "\n",
            "[[207  77]\n",
            " [  7   9]]\n",
            "112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes"
      ],
      "metadata": {
        "id": "Xc30xyX_eaRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate a Naive Bayes classifier without cost minimization\n",
        "clf = GaussianNB()\n",
        "print(\"No cost minimization\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T \n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "print(\"\\ncost minimization without probability calibration\")\n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "# Train and evaluate a Naive Bayes classifier with cost minimization (sigmoid calibration)\n",
        "print(\"\\nCost minimization with sigmoid calibration\")\n",
        "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
        "model = cc.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))\n",
        "\n",
        "print(\"\\ncost minimization with isotonic calibration\")\n",
        "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
        "model = cc.fit(X_train, y_train)\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1)+1\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "conf_m = confusion_matrix(y_test, y_pred).T\n",
        "print(conf_m) \n",
        "print(np.sum(conf_m * cost_m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chM5FEMaecCB",
        "outputId": "4bb8101b-aecf-4aad-aa03-24506051e590"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No cost minimization\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.84      0.73      0.78       214\n",
            "         bad       0.50      0.65      0.56        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.67      0.69      0.67       300\n",
            "weighted avg       0.74      0.71      0.72       300\n",
            "\n",
            "[[157  30]\n",
            " [ 57  56]]\n",
            "315\n",
            "\n",
            "cost minimization without probability calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.79      0.89      0.84       214\n",
            "         bad       0.60      0.41      0.49        86\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.70      0.65      0.66       300\n",
            "weighted avg       0.74      0.75      0.74       300\n",
            "\n",
            "[[191  51]\n",
            " [ 23  35]]\n",
            "166\n",
            "\n",
            "Cost minimization with sigmoid calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.71      1.00      0.83       214\n",
            "         bad       0.00      0.00      0.00        86\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.36      0.50      0.42       300\n",
            "weighted avg       0.51      0.71      0.59       300\n",
            "\n",
            "[[214  86]\n",
            " [  0   0]]\n",
            "86\n",
            "\n",
            "cost minimization with isotonic calibration\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.71      0.98      0.82       214\n",
            "         bad       0.17      0.01      0.02        86\n",
            "\n",
            "    accuracy                           0.70       300\n",
            "   macro avg       0.44      0.49      0.42       300\n",
            "weighted avg       0.55      0.70      0.59       300\n",
            "\n",
            "[[209  85]\n",
            " [  5   1]]\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we achieved a cost minimization in all three cases. In Random Forest the smallest cost was achieved in cost minimization without probability calibration. In SVM the smaller costs are noticed in cost minimization without probability calibration and sigmoid and lastly in Naive Bayes, cost minimization with sigmoid calibration has achieved also the smallest cost.\n",
        "Overall, calibration \"saves the case\" in Naive Bayes and in SVM, specifically with the sigmoid calibration only. In Random Forest we prefer cost minimization without probability calibration, while the isotonic calibration in SVM does not give the best results, while we note that the metrics of our classification report are the best in Naive Bayes, which also has the greatest minimization in the cost by using (especially sigmoid) calibration."
      ],
      "metadata": {
        "id": "JiKwRi_jte6F"
      }
    }
  ]
}
